{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_size = 500\n",
    "epochs = 3\n",
    "mini_batch = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74357 entries, 0 to 74356\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   MBTI    74357 non-null  object\n",
      " 1   words   74357 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "## 트레이닝 데이터셋이 저장된 파일을 읽고,\n",
    "## csv 파일의 첫째항부터 열이름 없이 데이터가 저장되어 있어서\n",
    "## 첫번째 데이터가 자꾸 column명으로 입력되길래 당황했다.\n",
    "## 새로운 행을 추가하는 방법도 생각해 봤는데 어려웠고...\n",
    "## 그래서 그냥 새로 만든 데이터프레임에 columns 명을 프로그램 안에서 지정해 주기로 했다.\n",
    "\n",
    "df_train = pd.read_csv(\"MBTI_train.csv\", names=[\"MBTI\", \"words\"])\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MBTI</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INTP</td>\n",
       "      <td>say process model list like subscriber channel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>upon much manipulate retail finish like sacrif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>fit yes certain bff social feel goal go know n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>complete love within someone ideal joke solvea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>public strictly thing person x question person...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MBTI                                              words\n",
       "0  INTP  say process model list like subscriber channel...\n",
       "1  INFJ  upon much manipulate retail finish like sacrif...\n",
       "2  INFJ  fit yes certain bff social feel goal go know n...\n",
       "3  INTJ  complete love within someone ideal joke solvea...\n",
       "4  ENTJ  public strictly thing person x question person..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_test = df_train.drop(df_train.index).copy()\n",
    "df_val = df_val_test.sample(frac=0.5, random_state=5).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## words를 학습데이터로 삼으면서\n",
    "## 각각의 words에 해당 MBTI 라벨을 붙였다.\n",
    "## 트레이닝용, 검증용 따로 정의함.\n",
    "\n",
    "labels_train = df_train['MBTI'].values\n",
    "data_train = df_train['words'].values\n",
    "\n",
    "labels_val = df_val['MBTI'].values\n",
    "data_val = df_val['words'].values\n",
    "\n",
    "le = LabelEncoder()\n",
    "en_labels_train = le.fit_transform(labels_train)\n",
    "en_labels_val = le.transform(labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'MBTI COUNT')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 트레이닝 데이터셋 파일에 있던\n",
    "## 각각의 MBTI 종류별로 존재하는 데이터량을\n",
    "## 그래프로 시각화함\n",
    "## 나중에 보니까 진짜 INTP INTJ가 대부분이더라...\n",
    "\n",
    "unique_labels, count = np.unique(df_train['MBTI'], return_counts=True)\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "plt.bar(unique_labels, count, color=\"YELLOW\", width=1)\n",
    "plt.title(\"MBTI COUNT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 단어들 토큰화 진행\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token='<UNK>')\n",
    "tokenizer.fit_on_texts(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 패딩하는 함수 정의\n",
    "\n",
    "def pad_data(tokenizer, data2pad, maxlen):\n",
    "    sequence = tokenizer.texts_to_sequences(data2pad)\n",
    "    paded = pad_sequences(sequence, truncating='post', padding='post', maxlen=maxlen)\n",
    "    return paded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20364/443335328.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## 훈련 데이터, 검증 데이터 각각 패딩\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpaded_data_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtxt_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mpaded_data_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtxt_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20364/3048637674.py\u001b[0m in \u001b[0;36mpad_data\u001b[1;34m(tokenizer, data2pad, maxlen)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpad_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata2pad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0msequence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata2pad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mpaded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncating\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'post'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'post'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mpaded\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras_preprocessing\\text.py\u001b[0m in \u001b[0;36mtexts_to_sequences\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    279\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0msequences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m         \"\"\"\n\u001b[1;32m--> 281\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtexts_to_sequences_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtexts_to_sequences_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras_preprocessing\\text.py\u001b[0m in \u001b[0;36mtexts_to_sequences_generator\u001b[1;34m(self, texts)\u001b[0m\n\u001b[0;32m    307\u001b[0m                 \u001b[0mseq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m                 seq = text_to_word_sequence(text,\n\u001b[0m\u001b[0;32m    310\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\keras_preprocessing\\text.py\u001b[0m in \u001b[0;36mtext_to_word_sequence\u001b[1;34m(text, filters, lower, split)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mtranslate_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0msplit\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mtranslate_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaketrans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranslate_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranslate_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mseq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## 훈련 데이터, 검증 데이터 각각 패딩\n",
    "\n",
    "paded_data_train = pad_data(tokenizer, data_train, txt_size)\n",
    "paded_data_val = pad_data(tokenizer, data_val, txt_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74357, 500)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paded_data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 vectorize\n",
    "\n",
    "def vectorize_text(text, label): \n",
    "    text = tf.expand_dims(text, -1) \n",
    "    return vectorize_layer(text), label \n",
    "\n",
    "max_features = 10000\n",
    "sequence_length = 500\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens=max_features, \n",
    "    output_mode=\"int\", \n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "vectorize_layer.adapt(data_train)\n",
    "vect_train = vectorize_layer(data_train)\n",
    "vect_val = vectorize_layer(data_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 모델 생성하는 함수 정의\n",
    "\n",
    "def create_model(post_size, num_labels):\n",
    "    inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
    "    \n",
    "    x = layers.Embedding(10000, 128)(inputs)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "    x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    predictions = layers.Dense(num_labels, activation=\"sigmoid\", name=\"predictions\")(x)\n",
    "    model = tf.keras.Model(inputs, predictions)\n",
    "    return model\n",
    "\n",
    "def show_history(h):\n",
    "    epochs_trained = len(h.history['loss'])\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(0, epochs_trained), h.history.get('accuracy'), label='Training')\n",
    "    plt.plot(range(0, epochs_trained), h.history.get('val_accuracy'), label='Validation')\n",
    "    plt.ylim([0., 1.])\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(0, epochs_trained), h.history.get('loss'), label='Training')\n",
    "    plt.plot(range(0, epochs_trained), h.history.get('val_loss'), label='Validation')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 128)         1280000   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 128)         0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, None, 128)         114816    \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, None, 128)         114816    \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 128)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 16)                2064      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,528,208\n",
      "Trainable params: 1,528,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_token = create_model(txt_size, len(unique_labels))\n",
    "model_token.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_token.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2324/2324 [==============================] - ETA: 0s - loss: 1.6179 - accuracy: 0.4867WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
      "2324/2324 [==============================] - 440s 188ms/step - loss: 1.6179 - accuracy: 0.4867\n",
      "Epoch 2/2\n",
      "2324/2324 [==============================] - ETA: 0s - loss: 1.1303 - accuracy: 0.6628WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
      "2324/2324 [==============================] - 368s 158ms/step - loss: 1.1303 - accuracy: 0.6628\n"
     ]
    }
   ],
   "source": [
    "## 모델 훈련시키기\n",
    "\n",
    "history_token = model_token.fit(\n",
    "    paded_data_train, en_labels_train,\n",
    "    validation_data = (paded_data_val, en_labels_val),\n",
    "    epochs = epochs,\n",
    "    batch_size = mini_batch,\n",
    "    callbacks=[\n",
    "               tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9337 entries, 0 to 9336\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   MBTI    0 non-null      object\n",
      " 1   words   9337 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 146.0+ KB\n"
     ]
    }
   ],
   "source": [
    "## 이제 테스트할 차례\n",
    "## 테스트 데이터셋 저장된 파일 불러오기\n",
    "\n",
    "text_batch = data_val\n",
    "label_batch = data_val\n",
    "\n",
    "df_test = pd.read_csv(\"MBTI_test.csv\", names=[\"words\"])\n",
    "df_test['MBTI'] = np.nan\n",
    "df_test = df_test[['MBTI', 'words']]\n",
    "df_test = df_test.astype({'MBTI':'object'})\n",
    "df_test.info()\n",
    "\n",
    "labels_test = df_test['MBTI'].values\n",
    "data_test = df_test['words'].values\n",
    "paded_data_test = pad_data(tokenizer, data_test, txt_size)\n",
    "vect_test = vectorize_layer(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 예측 모델 생성\n",
    "\n",
    "inference = model_token.predict_on_batch(vect_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENFJ</th>\n",
       "      <th>ENFP</th>\n",
       "      <th>ENTJ</th>\n",
       "      <th>ENTP</th>\n",
       "      <th>ESFJ</th>\n",
       "      <th>ESFP</th>\n",
       "      <th>ESTJ</th>\n",
       "      <th>ESTP</th>\n",
       "      <th>INFJ</th>\n",
       "      <th>INFP</th>\n",
       "      <th>INTJ</th>\n",
       "      <th>INTP</th>\n",
       "      <th>ISFJ</th>\n",
       "      <th>ISFP</th>\n",
       "      <th>ISTJ</th>\n",
       "      <th>ISTP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.518537</td>\n",
       "      <td>0.989429</td>\n",
       "      <td>0.072004</td>\n",
       "      <td>0.066087</td>\n",
       "      <td>0.006665</td>\n",
       "      <td>0.025757</td>\n",
       "      <td>1.952052e-04</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.697332</td>\n",
       "      <td>0.780481</td>\n",
       "      <td>0.119343</td>\n",
       "      <td>0.013228</td>\n",
       "      <td>0.058952</td>\n",
       "      <td>0.150026</td>\n",
       "      <td>0.098208</td>\n",
       "      <td>0.005113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.153921</td>\n",
       "      <td>0.094294</td>\n",
       "      <td>0.287124</td>\n",
       "      <td>0.995333</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.004937</td>\n",
       "      <td>1.101356e-04</td>\n",
       "      <td>0.029807</td>\n",
       "      <td>0.781314</td>\n",
       "      <td>0.278508</td>\n",
       "      <td>0.384041</td>\n",
       "      <td>0.600946</td>\n",
       "      <td>0.030973</td>\n",
       "      <td>0.026916</td>\n",
       "      <td>0.035131</td>\n",
       "      <td>0.070328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.028955</td>\n",
       "      <td>0.952374</td>\n",
       "      <td>0.745793</td>\n",
       "      <td>0.395842</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>5.260671e-07</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.315601</td>\n",
       "      <td>0.233377</td>\n",
       "      <td>0.997885</td>\n",
       "      <td>0.508927</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.152442</td>\n",
       "      <td>0.027656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.543518</td>\n",
       "      <td>0.875947</td>\n",
       "      <td>0.658192</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>1.299200e-08</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.363087</td>\n",
       "      <td>0.161309</td>\n",
       "      <td>0.999893</td>\n",
       "      <td>0.970863</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.262920</td>\n",
       "      <td>0.078813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.090935</td>\n",
       "      <td>0.058578</td>\n",
       "      <td>0.739373</td>\n",
       "      <td>0.600214</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>4.480776e-05</td>\n",
       "      <td>0.009818</td>\n",
       "      <td>0.129361</td>\n",
       "      <td>0.391241</td>\n",
       "      <td>0.996780</td>\n",
       "      <td>0.999143</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.004174</td>\n",
       "      <td>0.163630</td>\n",
       "      <td>0.702166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ENFJ      ENFP      ENTJ      ENTP      ESFJ      ESFP          ESTJ  \\\n",
       "0  0.518537  0.989429  0.072004  0.066087  0.006665  0.025757  1.952052e-04   \n",
       "1  0.153921  0.094294  0.287124  0.995333  0.000529  0.004937  1.101356e-04   \n",
       "2  0.028955  0.952374  0.745793  0.395842  0.000196  0.001102  5.260671e-07   \n",
       "3  0.007937  0.543518  0.875947  0.658192  0.000013  0.000069  1.299200e-08   \n",
       "4  0.090935  0.058578  0.739373  0.600214  0.001548  0.000593  4.480776e-05   \n",
       "\n",
       "       ESTP      INFJ      INFP      INTJ      INTP      ISFJ      ISFP  \\\n",
       "0  0.000047  0.697332  0.780481  0.119343  0.013228  0.058952  0.150026   \n",
       "1  0.029807  0.781314  0.278508  0.384041  0.600946  0.030973  0.026916   \n",
       "2  0.000202  0.315601  0.233377  0.997885  0.508927  0.000259  0.001736   \n",
       "3  0.000313  0.363087  0.161309  0.999893  0.970863  0.000051  0.000093   \n",
       "4  0.009818  0.129361  0.391241  0.996780  0.999143  0.000492  0.004174   \n",
       "\n",
       "       ISTJ      ISTP  \n",
       "0  0.098208  0.005113  \n",
       "1  0.035131  0.070328  \n",
       "2  0.152442  0.027656  \n",
       "3  0.262920  0.078813  \n",
       "4  0.163630  0.702166  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 예측한 값을 새로운 데이터프레임에 넣어주고\n",
    "## columns명을 각 MBTI로 설정\n",
    "\n",
    "resultDF = pd.DataFrame(inference)\n",
    "resultDF.columns = unique_labels\n",
    "resultDF.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.989429\n",
       "1    0.995333\n",
       "2    0.997885\n",
       "3    0.999893\n",
       "4    0.999143\n",
       "dtype: float32"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = resultDF.max(axis=1)\n",
    "\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ENFP\n",
       "1    ENTP\n",
       "2    INTJ\n",
       "3    INTJ\n",
       "4    INTP\n",
       "dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = resultDF.idxmax(axis=1)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(result, columns=['MBTI'])\n",
    "result.to_csv(\"Final_result_team14.csv\", index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
